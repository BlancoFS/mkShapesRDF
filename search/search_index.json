{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to mkShapesRDF Run the setup command: . ./setup.sh Configure the configuration folder (e.g. 2016Real) with the main files: aliases.py configuration.py cuts.py nuisances.py plot.py samples.py variables.py Run the analysis: python mkShapesRDFParallel.py -o 0 -f 2016Real -b 1 -o indicates the operationMode: - 0 run analysis - 1 check batch output and errs - 2 merge root files - 3 plot them For the provided example (2016Real) it's estimated an execution time of ~ 10 mins running on lxbatch (condor on lxplus) @ CERN. It's highly recommended to limit input ROOT files at the first run to check for errors. The following command will only take 1 file for each sample type: python mkShapesRDFParallel.py -o 0 -f 2016Real -l 1 Check for errors After all the jobs finished (or most of them did) you can run mkShapesRDFParallel.py -o 1 -f 2016Real to know which jobs failed and why Merge files If all the jobs succeeded run the merger with the option: python mkShapesRDFParallel.py -o 2 -f 2016Real Plots Plot with python mkShapesRDFParallel.py -o 3 -f 2016Real which will create the plots to the specified paths provided in configuration.py Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Home"},{"location":"#welcome-to-mkshapesrdf","text":"","title":"Welcome to mkShapesRDF"},{"location":"#run-the-setup-command","text":". ./setup.sh","title":"Run the setup command:"},{"location":"#configure-the-configuration-folder-eg-2016real-with-the-main-files","text":"aliases.py configuration.py cuts.py nuisances.py plot.py samples.py variables.py","title":"Configure the configuration folder (e.g. 2016Real) with the main files:"},{"location":"#run-the-analysis","text":"python mkShapesRDFParallel.py -o 0 -f 2016Real -b 1 -o indicates the operationMode: - 0 run analysis - 1 check batch output and errs - 2 merge root files - 3 plot them For the provided example (2016Real) it's estimated an execution time of ~ 10 mins running on lxbatch (condor on lxplus) @ CERN. It's highly recommended to limit input ROOT files at the first run to check for errors. The following command will only take 1 file for each sample type: python mkShapesRDFParallel.py -o 0 -f 2016Real -l 1","title":"Run the analysis:"},{"location":"#check-for-errors","text":"After all the jobs finished (or most of them did) you can run mkShapesRDFParallel.py -o 1 -f 2016Real to know which jobs failed and why","title":"Check for errors"},{"location":"#merge-files","text":"If all the jobs succeeded run the merger with the option: python mkShapesRDFParallel.py -o 2 -f 2016Real","title":"Merge files"},{"location":"#plots","text":"Plot with python mkShapesRDFParallel.py -o 3 -f 2016Real which will create the plots to the specified paths provided in configuration.py","title":"Plots"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"folder/","text":"Main structure Configuration File Samples Aliases Cuts Variables Nuisances","title":"Configuration Folder Structure"},{"location":"folder/#main-structure","text":"","title":"Main structure"},{"location":"folder/#configuration-file","text":"","title":"Configuration File"},{"location":"folder/#samples","text":"","title":"Samples"},{"location":"folder/#aliases","text":"","title":"Aliases"},{"location":"folder/#cuts","text":"","title":"Cuts"},{"location":"folder/#variables","text":"","title":"Variables"},{"location":"folder/#nuisances","text":"","title":"Nuisances"},{"location":"mkShapesRDF/","text":"","title":"mkShapesRDF"},{"location":"runner/","text":"Documentation for Runner runner . RunAnalysis . splitSamples ( samples , useFilesPerJob = True ) staticmethod static methods, takes a dictionary of samples and split them based on their weights and max num. of files Parameters: Name Type Description Default samples dict dictionary of samples required useFilesPerJob bool if you want to further split the samples based on max num. of files. Defaults to True. True Returns: Type Description list of tuples each tuple will have a lenght of 5 (6 if subsamples are present), where the first element is the name of the sample, the second the list of files, the third the weight, and the fourth the index of this tuple compared to the other tuples of the same sample type, the fifth will be the isData flag (True if the sample is data, False otherwise). If subsamples are present, the sixth element will be the dict of subsamples runner . RunAnalysis . __init__ ( samples , aliases , variables , preselections , cuts , nuisances , lumi , limit =- 1 , outputFileMap = 'output.root' ) Stores arguments in the class attributes and creates all the RDataFrame objects Parameters: Name Type Description Default samples list of tuples same type as the return of the splitSamples method required aliases dict dict of aliases required variables dict dict of variables required preselections str string with the preselections required cuts dict dict of cuts required nuisances dict dict of nuisances required lumi float lumi in fb-1 required limit int limit of events to be processed. Defaults to -1. -1 outputFileMap str full path + filename of the output root file. Defaults to 'output.root'. 'output.root' Returns: Type Description void void The main function: runner . RunAnalysis . run () Runs the analysis, first loads the aliases, filters with preselection the many dfs, loads systematics loads variables, creates the results dict, splits the samples, creates the cuts/var histos, runs the analysis and saves results. Runner should be provided with samples, aliases and all the other configuration dictionaries. It will determine how to split the sample splitting and merging of results","title":"Runner"},{"location":"runner/#documentation-for-runner","text":"","title":"Documentation for Runner"},{"location":"runner/#runner.RunAnalysis.splitSamples","text":"static methods, takes a dictionary of samples and split them based on their weights and max num. of files Parameters: Name Type Description Default samples dict dictionary of samples required useFilesPerJob bool if you want to further split the samples based on max num. of files. Defaults to True. True Returns: Type Description list of tuples each tuple will have a lenght of 5 (6 if subsamples are present), where the first element is the name of the sample, the second the list of files, the third the weight, and the fourth the index of this tuple compared to the other tuples of the same sample type, the fifth will be the isData flag (True if the sample is data, False otherwise). If subsamples are present, the sixth element will be the dict of subsamples","title":"splitSamples()"},{"location":"runner/#runner.RunAnalysis.__init__","text":"Stores arguments in the class attributes and creates all the RDataFrame objects Parameters: Name Type Description Default samples list of tuples same type as the return of the splitSamples method required aliases dict dict of aliases required variables dict dict of variables required preselections str string with the preselections required cuts dict dict of cuts required nuisances dict dict of nuisances required lumi float lumi in fb-1 required limit int limit of events to be processed. Defaults to -1. -1 outputFileMap str full path + filename of the output root file. Defaults to 'output.root'. 'output.root' Returns: Type Description void void","title":"__init__()"},{"location":"runner/#the-main-function","text":"","title":"The main function:"},{"location":"runner/#runner.RunAnalysis.run","text":"Runs the analysis, first loads the aliases, filters with preselection the many dfs, loads systematics loads variables, creates the results dict, splits the samples, creates the cuts/var histos, runs the analysis and saves results. Runner should be provided with samples, aliases and all the other configuration dictionaries. It will determine how to split the sample splitting and merging of results","title":"run()"}]}